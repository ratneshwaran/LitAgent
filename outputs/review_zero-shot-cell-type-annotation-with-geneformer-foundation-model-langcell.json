{
  "topic": "zero shot cell type annotation with geneformer foundation model langcell",
  "filters": {
    "start_year": null,
    "end_year": null,
    "include_keywords": [],
    "exclude_keywords": [],
    "venues": [],
    "limit": 10
  },
  "raw_papers": [
    {
      "id": "http://arxiv.org/abs/2411.06331v1",
      "source": "arxiv",
      "title": "GenoHoption: Bridging Gene Network Graphs and Single-Cell Foundation\n  Models",
      "abstract": "The remarkable success of foundation models has sparked growing interest in\ntheir application to single-cell biology. Models like Geneformer and scGPT\npromise to serve as versatile tools in this specialized field. However,\nrepresenting a cell as a sequence of genes remains an open question since the\norder of genes is interchangeable. Injecting the gene network graph offers gene\nrelative positions and compact data representation but poses a dilemma: limited\nreceptive fields without in-layer message passing or parameter explosion with\nmessage passing in each layer. To pave the way forward, we propose GenoHoption,\na new computational framework for single-cell sequencing data that effortlessly\ncombines the strengths of these foundation models with explicit relationships\nin gene networks. We also introduce a constraint that lightens the model by\nfocusing on learning the predefined graph structure while ensuring further hops\nare deducted to expand the receptive field. Empirical studies show that our\nmodel improves by an average of 1.27% on cell-type annotation and 3.86% on\nperturbation prediction. Furthermore, our method significantly decreases\ncomputational overhead and exhibits few-shot potential. GenoHoption can\nfunction as an efficient and expressive bridge, connecting existing single-cell\nfoundation models to gene network graphs.",
      "authors": [
        "Jiabei Cheng",
        "Jiachen Li",
        "Kaiyuan Yang",
        "Hongbin Shen",
        "Ye Yuan"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2411.06331v1",
      "pdf_url": "http://arxiv.org/pdf/2411.06331v1",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2402.12405v1",
      "source": "arxiv",
      "title": "scInterpreter: Training Large Language Models to Interpret scRNA-seq\n  Data for Cell Type Annotation",
      "abstract": "Despite the inherent limitations of existing Large Language Models in\ndirectly reading and interpreting single-cell omics data, they demonstrate\nsignificant potential and flexibility as the Foundation Model. This research\nfocuses on how to train and adapt the Large Language Model with the capability\nto interpret and distinguish cell types in single-cell RNA sequencing data. Our\npreliminary research results indicate that these foundational models excel in\naccurately categorizing known cell types, demonstrating the potential of the\nLarge Language Models as effective tools for uncovering new biological\ninsights.",
      "authors": [
        "Cong Li",
        "Meng Xiao",
        "Pengfei Wang",
        "Guihai Feng",
        "Xin Li",
        "Yuanchun Zhou"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2402.12405v1",
      "pdf_url": "http://arxiv.org/pdf/2402.12405v1",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2508.04747v1",
      "source": "arxiv",
      "title": "GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type\n  Annotation",
      "abstract": "Cell type annotation is a fundamental step in the analysis of single-cell RNA\nsequencing (scRNA-seq) data. In practice, human experts often rely on the\nstructure revealed by principal component analysis (PCA) followed by\n$k$-nearest neighbor ($k$-NN) graph construction to guide annotation. While\neffective, this process is labor-intensive and does not scale to large\ndatasets. Recent advances in CLIP-style models offer a promising path toward\nautomating cell type annotation. By aligning scRNA-seq profiles with natural\nlanguage descriptions, models like LangCell enable zero-shot annotation. While\nLangCell demonstrates decent zero-shot performance, its predictions remain\nsuboptimal, particularly in achieving consistent accuracy across all cell\ntypes. In this paper, we propose to refine the zero-shot logits produced by\nLangCell through a graph-regularized optimization framework. By enforcing local\nconsistency over the task-specific PCA-based k-NN graph, our method combines\nthe scalability of the pre-trained models with the structural robustness relied\nupon in expert annotation. We evaluate our approach on 14 annotated human\nscRNA-seq datasets from 4 distinct studies, spanning 11 organs and over 200,000\nsingle cells. Our method consistently improves zero-shot annotation accuracy,\nachieving accuracy gains of up to 10%. Further analysis showcase the mechanism\nby which GRIT effectively propagates correct signals through the graph, pulling\nback mislabeled cells toward more accurate predictions. The method is\ntraining-free, model-agnostic, and serves as a simple yet effective plug-in for\nenhancing automated cell type annotation in practice.",
      "authors": [
        "Tianxiang Hu",
        "Chenyi Zhou",
        "Jiaxiang Liu",
        "Jiongxin Wang",
        "Ruizhe Chen",
        "Haoxiang Xia",
        "Gaoang Wang",
        "Jian Wu",
        "Zuozhu Liu"
      ],
      "year": 2025,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2508.04747v1",
      "pdf_url": "http://arxiv.org/pdf/2508.04747v1",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2505.12638v2",
      "source": "arxiv",
      "title": "ChromFound: Towards A Universal Foundation Model for Single-Cell\n  Chromatin Accessibility Data",
      "abstract": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achieved significant success\nin single-cell transcriptomics, there is currently no foundation model for\nscATAC-seq that supports zero-shot high-quality cell identification and\ncomprehensive multi-omics analysis simultaneously. Key challenges lie in the\nhigh dimensionality and sparsity of scATAC-seq data, as well as the lack of a\nstandardized schema for representing open chromatin regions (OCRs). Here, we\npresent ChromFound, a foundation model tailored for scATAC-seq. ChromFound\nutilizes a hybrid architecture and genome-aware tokenization to effectively\ncapture genome-wide long contexts and regulatory signals from dynamic chromatin\nlandscapes. Pretrained on 1.97 million cells from 30 tissues and 6 disease\nconditions, ChromFound demonstrates broad applicability across 6 diverse tasks.\nNotably, it achieves robust zero-shot performance in generating universal cell\nrepresentations and exhibits excellent transferability in cell type annotation\nand cross-omics prediction. By uncovering enhancer-gene links undetected by\nexisting computational methods, ChromFound offers a promising framework for\nunderstanding disease risk variants in the noncoding genome.",
      "authors": [
        "Yifeng Jiao",
        "Yuchen Liu",
        "Yu Zhang",
        "Xin Guo",
        "Yushuai Wu",
        "Chen Jiang",
        "Jiyang Li",
        "Hongwei Zhang",
        "Limei Han",
        "Xin Gao",
        "Yuan Qi",
        "Yuan Cheng"
      ],
      "year": 2025,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2505.12638v2",
      "pdf_url": "http://arxiv.org/pdf/2505.12638v2",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2508.15751v1",
      "source": "arxiv",
      "title": "Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered\n  All-in-SAM Model",
      "abstract": "Purpose: Recent developments in computational pathology have been driven by\nadvances in Vision Foundation Models, particularly the Segment Anything Model\n(SAM). This model facilitates nuclei segmentation through two primary methods:\nprompt-based zero-shot segmentation and the use of cell-specific SAM models for\ndirect segmentation. These approaches enable effective segmentation across a\nrange of nuclei and cells. However, general vision foundation models often face\nchallenges with fine-grained semantic segmentation, such as identifying\nspecific nuclei subtypes or particular cells. Approach: In this paper, we\npropose the molecular-empowered All-in-SAM Model to advance computational\npathology by leveraging the capabilities of vision foundation models. This\nmodel incorporates a full-stack approach, focusing on: (1) annotation-engaging\nlay annotators through molecular-empowered learning to reduce the need for\ndetailed pixel-level annotations, (2) learning-adapting the SAM model to\nemphasize specific semantics, which utilizes its strong generalizability with\nSAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating\nMolecular-Oriented Corrective Learning (MOCL). Results: Experimental results\nfrom both in-house and public datasets show that the All-in-SAM model\nsignificantly improves cell classification performance, even when faced with\nvarying annotation quality. Conclusions: Our approach not only reduces the\nworkload for annotators but also extends the accessibility of precise\nbiomedical image analysis to resource-limited settings, thereby advancing\nmedical diagnostics and automating pathology image analysis.",
      "authors": [
        "Xueyuan Li",
        "Can Cui",
        "Ruining Deng",
        "Yucheng Tang",
        "Quan Liu",
        "Tianyuan Yao",
        "Shunxing Bao",
        "Naweed Chowdhury",
        "Haichun Yang",
        "Yuankai Huo"
      ],
      "year": 2025,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2508.15751v1",
      "pdf_url": "http://arxiv.org/pdf/2508.15751v1",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2507.04270v3",
      "source": "arxiv",
      "title": "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts",
      "abstract": "Foundation models have revolutionized AI, yet they struggle with zero-shot\ndeployment in real-world industrial settings due to a lack of high-quality,\ndomain-specific datasets. To bridge this gap, Superb AI introduces ZERO, an\nindustry-ready vision foundation model that leverages multi-modal prompting\n(textual and visual) for generalization without retraining. Trained on a\ncompact yet representative 0.9 million annotated samples from a proprietary\nbillion-scale industrial dataset, ZERO demonstrates competitive performance on\nacademic benchmarks like LVIS-Val and significantly outperforms existing models\nacross 37 diverse industrial datasets. Furthermore, ZERO achieved 2nd place in\nthe CVPR 2025 Object Instance Detection Challenge and 4th place in the\nFoundational Few-shot Object Detection Challenge, highlighting its practical\ndeployability and generalizability with minimal adaptation and limited data. To\nthe best of our knowledge, ZERO is the first vision foundation model explicitly\nbuilt for domain-specific, zero-shot industrial applications.",
      "authors": [
        "Sangbum Choi",
        "Kyeongryeol Go",
        "Taewoong Jang"
      ],
      "year": 2025,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2507.04270v3",
      "pdf_url": "http://arxiv.org/pdf/2507.04270v3",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2405.06708v5",
      "source": "arxiv",
      "title": "LangCell: Language-Cell Pre-training for Cell Identity Understanding",
      "abstract": "Cell identity encompasses various semantic aspects of a cell, including cell\ntype, pathway information, disease information, and more, which are essential\nfor biologists to gain insights into its biological characteristics.\nUnderstanding cell identity from the transcriptomic data, such as annotating\ncell types, has become an important task in bioinformatics. As these semantic\naspects are determined by human experts, it is impossible for AI models to\neffectively carry out cell identity understanding tasks without the supervision\nsignals provided by single-cell and label pairs. The single-cell pre-trained\nlanguage models (PLMs) currently used for this task are trained only on a\nsingle modality, transcriptomics data, lack an understanding of cell identity\nknowledge. As a result, they have to be fine-tuned for downstream tasks and\nstruggle when lacking labeled data with the desired semantic labels. To address\nthis issue, we propose an innovative solution by constructing a unified\nrepresentation of single-cell data and natural language during the pre-training\nphase, allowing the model to directly incorporate insights related to cell\nidentity. More specifically, we introduce $\\textbf{LangCell}$, the first\n$\\textbf{Lang}$uage-$\\textbf{Cell}$ pre-training framework. LangCell utilizes\ntexts enriched with cell identity information to gain a profound comprehension\nof cross-modal knowledge. Results from experiments conducted on different\nbenchmarks show that LangCell is the only single-cell PLM that can work\neffectively in zero-shot cell identity understanding scenarios, and also\nsignificantly outperforms existing models in few-shot and fine-tuning cell\nidentity understanding scenarios.",
      "authors": [
        "Suyuan Zhao",
        "Jiahuan Zhang",
        "Yushuai Wu",
        "Yizhen Luo",
        "Zaiqing Nie"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2405.06708v5",
      "pdf_url": "http://arxiv.org/pdf/2405.06708v5",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2412.13478v2",
      "source": "arxiv",
      "title": "Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot\n  Molecular Perturbation Prediction",
      "abstract": "Predicting transcriptional responses to novel drugs provides a unique\nopportunity to accelerate biomedical research and advance drug discovery\nefforts. However, the inherent complexity and high dimensionality of cellular\nresponses, combined with the extremely limited available experimental data,\nmakes the task challenging. In this study, we leverage single-cell foundation\nmodels (FMs) pre-trained on tens of millions of single cells, encompassing\nmultiple cell types, states, and disease annotations, to address molecular\nperturbation prediction. We introduce a drug-conditional adapter that allows\nefficient fine-tuning by training less than 1% of the original foundation\nmodel, thus enabling molecular conditioning while preserving the rich\nbiological representation learned during pre-training. The proposed strategy\nallows not only the prediction of cellular responses to novel drugs, but also\nthe zero-shot generalization to unseen cell lines. We establish a robust\nevaluation framework to assess model performance across different\ngeneralization tasks, demonstrating state-of-the-art results across all\nsettings, with significant improvements in the few-shot and zero-shot\ngeneralization to new cell lines compared to existing baselines.",
      "authors": [
        "Sepideh Maleki",
        "Jan-Christian Huetter",
        "Kangway V. Chuang",
        "David Richmond",
        "Gabriele Scalia",
        "Tommaso Biancalani"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2412.13478v2",
      "pdf_url": "http://arxiv.org/pdf/2412.13478v2",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2408.12373v2",
      "source": "arxiv",
      "title": "Cell-ontology guided transcriptome foundation model",
      "abstract": "Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expression data, and ultimately\nunraveling the complex mechanisms of human diseases. However, current TFMs\ntreat cells as independent samples and ignore the taxonomic relationships\nbetween cell types, which are available in cell ontology graphs. We argue that\neffectively leveraging this ontology information during the TFM pre-training\ncan improve learning biologically meaningful gene co-expression patterns while\npreserving TFM as a general purpose foundation model for downstream zero-shot\nand fine-tuning tasks. To this end, we present single cell, Cell-ontology\nguided TFM scCello. We introduce cell-type coherence loss and ontology\nalignment loss, which are minimized along with the masked gene expression\nprediction loss during the pre-training. The novel loss component guide scCello\nto learn the cell-type-specific representation and the structural relation\nbetween cell types from the cell ontology graph, respectively. We pre-trained\nscCello on 22 million cells from CellxGene database leveraging their cell-type\nlabels mapped to the cell ontology graph from Open Biological and Biomedical\nOntology Foundry. Our TFM demonstrates competitive generalization and\ntransferability performance over the existing TFMs on biologically important\ntasks including identifying novel cell types of unseen cells, prediction of\ncell-type-specific marker genes, and cancer drug responses.",
      "authors": [
        "Xinyu Yuan",
        "Zhihao Zhan",
        "Zuobai Zhang",
        "Manqi Zhou",
        "Jianan Zhao",
        "Boyu Han",
        "Yue Li",
        "Jian Tang"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2408.12373v2",
      "pdf_url": "http://arxiv.org/pdf/2408.12373v2",
      "citations_count": null,
      "keywords": []
    },
    {
      "id": "http://arxiv.org/abs/2402.01188v4",
      "source": "arxiv",
      "title": "Segment Any Change",
      "abstract": "Visual foundation models have achieved remarkable results in zero-shot image\nclassification and segmentation, but zero-shot change detection remains an open\nproblem. In this paper, we propose the segment any change models (AnyChange), a\nnew type of change detection model that supports zero-shot prediction and\ngeneralization on unseen change types and data distributions. AnyChange is\nbuilt on the segment anything model (SAM) via our training-free adaptation\nmethod, bitemporal latent matching. By revealing and exploiting intra-image and\ninter-image semantic similarities in SAM's latent space, bitemporal latent\nmatching endows SAM with zero-shot change detection capabilities in a\ntraining-free way. We also propose a point query mechanism to enable\nAnyChange's zero-shot object-centric change detection capability. We perform\nextensive experiments to confirm the effectiveness of AnyChange for zero-shot\nchange detection. AnyChange sets a new record on the SECOND benchmark for\nunsupervised change detection, exceeding the previous SOTA by up to 4.4% F$_1$\nscore, and achieving comparable accuracy with negligible manual annotations (1\npixel per image) for supervised change detection. Code is available at\nhttps://github.com/Z-Zheng/pytorch-change-models.",
      "authors": [
        "Zhuo Zheng",
        "Yanfei Zhong",
        "Liangpei Zhang",
        "Stefano Ermon"
      ],
      "year": 2024,
      "venue": "arXiv",
      "doi": null,
      "url": "http://arxiv.org/abs/2402.01188v4",
      "pdf_url": "http://arxiv.org/pdf/2402.01188v4",
      "citations_count": null,
      "keywords": []
    }
  ],
  "reviews": [
    {
      "paper_id": "http://arxiv.org/abs/2411.06331v1",
      "summary": {
        "tldr": "The remarkable success of foundation models has sparked growing interest in\ntheir application to single-cell biology. Models like Geneformer and scGPT\npromise to serve as versatile tools in this specialized field. However,\nrepresenting a cell as a sequence of genes remains an ope...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "The remarkable success of foundation models has sparked growing interest in\ntheir application to single-cell biology. Models like Geneformer and scGPT\npromise to serve as versatile tools in this speci",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2402.12405v1",
      "summary": {
        "tldr": "Despite the inherent limitations of existing Large Language Models in\ndirectly reading and interpreting single-cell omics data, they demonstrate\nsignificant potential and flexibility as the Foundation Model. This research\nfocuses on how to train and adapt the Large Language Model...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Despite the inherent limitations of existing Large Language Models in\ndirectly reading and interpreting single-cell omics data, they demonstrate\nsignificant potential and flexibility as the Foundation",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2508.04747v1",
      "summary": {
        "tldr": "Cell type annotation is a fundamental step in the analysis of single-cell RNA\nsequencing (scRNA-seq) data. In practice, human experts often rely on the\nstructure revealed by principal component analysis (PCA) followed by\n$k$-nearest neighbor ($k$-NN) graph construction to guide a...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Cell type annotation is a fundamental step in the analysis of single-cell RNA\nsequencing (scRNA-seq) data. In practice, human experts often rely on the\nstructure revealed by principal component analys",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2505.12638v2",
      "summary": {
        "tldr": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repository of single-cell chromatin\naccessibility data. While foundation models have achi...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "The advent of single-cell Assay for Transposase-Accessible Chromatin using\nsequencing (scATAC-seq) offers an innovative perspective for deciphering\nregulatory mechanisms by assembling a vast repositor",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2508.15751v1",
      "summary": {
        "tldr": "Purpose: Recent developments in computational pathology have been driven by\nadvances in Vision Foundation Models, particularly the Segment Anything Model\n(SAM). This model facilitates nuclei segmentation through two primary methods:\nprompt-based zero-shot segmentation and the use...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Purpose: Recent developments in computational pathology have been driven by\nadvances in Vision Foundation Models, particularly the Segment Anything Model\n(SAM). This model facilitates nuclei segmentat",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2507.04270v3",
      "summary": {
        "tldr": "Foundation models have revolutionized AI, yet they struggle with zero-shot\ndeployment in real-world industrial settings due to a lack of high-quality,\ndomain-specific datasets. To bridge this gap, Superb AI introduces ZERO, an\nindustry-ready vision foundation model that leverages...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Foundation models have revolutionized AI, yet they struggle with zero-shot\ndeployment in real-world industrial settings due to a lack of high-quality,\ndomain-specific datasets. To bridge this gap, Sup",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2405.06708v5",
      "summary": {
        "tldr": "Cell identity encompasses various semantic aspects of a cell, including cell\ntype, pathway information, disease information, and more, which are essential\nfor biologists to gain insights into its biological characteristics.\nUnderstanding cell identity from the transcriptomic data...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Cell identity encompasses various semantic aspects of a cell, including cell\ntype, pathway information, disease information, and more, which are essential\nfor biologists to gain insights into its biol",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2412.13478v2",
      "summary": {
        "tldr": "Predicting transcriptional responses to novel drugs provides a unique\nopportunity to accelerate biomedical research and advance drug discovery\nefforts. However, the inherent complexity and high dimensionality of cellular\nresponses, combined with the extremely limited available ex...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Predicting transcriptional responses to novel drugs provides a unique\nopportunity to accelerate biomedical research and advance drug discovery\nefforts. However, the inherent complexity and high dimens",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2408.12373v2",
      "summary": {
        "tldr": "Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expression data, and ultimately\nunraveling the complex mechanisms of human diseases....",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expr",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    },
    {
      "paper_id": "http://arxiv.org/abs/2402.01188v4",
      "summary": {
        "tldr": "Visual foundation models have achieved remarkable results in zero-shot image\nclassification and segmentation, but zero-shot change detection remains an open\nproblem. In this paper, we propose the segment any change models (AnyChange), a\nnew type of change detection model that sup...",
        "methods": null,
        "results": null,
        "limitations": null,
        "citations": null,
        "grounding_score": 0.2,
        "quotes": [
          {
            "text": "Visual foundation models have achieved remarkable results in zero-shot image\nclassification and segmentation, but zero-shot change detection remains an open\nproblem. In this paper, we propose the segm",
            "section": "abstract"
          }
        ]
      },
      "critique": {
        "issues": [
          {
            "tag": "missing_baselines",
            "severity": "low",
            "rationale": "Results do not clearly compare against established baselines."
          },
          {
            "tag": "reproducibility",
            "severity": "medium",
            "rationale": "No mention of code/data availability or reproducibility."
          }
        ],
        "overall_note": null
      }
    }
  ],
  "matrix": {
    "columns": [
      "Venue",
      "Year",
      "Citations",
      "Methods",
      "Results",
      "Limitations"
    ],
    "rows": [
      "GenoHoption: Bridging Gene Network Graphs and Single-Cell Foundation\n  Models",
      "scInterpreter: Training Large Language Models to Interpret scRNA-seq\n  Data for Cell Type Annotation",
      "GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type\n  Annotation",
      "ChromFound: Towards A Universal Foundation Model for Single-Cell\n  Chromatin Accessibility Data",
      "Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered\n  All-in-SAM Model",
      "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts",
      "LangCell: Language-Cell Pre-training for Cell Identity Understanding",
      "Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot\n  Molecular Perturbation Prediction",
      "Cell-ontology guided transcriptome foundation model",
      "Segment Any Change"
    ],
    "data": {
      "GenoHoption: Bridging Gene Network Graphs and Single-Cell Foundation\n  Models": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "scInterpreter: Training Large Language Models to Interpret scRNA-seq\n  Data for Cell Type Annotation": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type\n  Annotation": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2025"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "ChromFound: Towards A Universal Foundation Model for Single-Cell\n  Chromatin Accessibility Data": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2025"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered\n  All-in-SAM Model": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2025"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2025"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "LangCell: Language-Cell Pre-training for Cell Identity Understanding": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "Efficient Fine-Tuning of Single-Cell Foundation Models Enables Zero-Shot\n  Molecular Perturbation Prediction": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "Cell-ontology guided transcriptome foundation model": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      },
      "Segment Any Change": {
        "Venue": {
          "value": "arXiv"
        },
        "Year": {
          "value": "2024"
        },
        "Citations": {
          "value": ""
        },
        "Methods": {
          "value": ""
        },
        "Results": {
          "value": ""
        },
        "Limitations": {
          "value": ""
        }
      }
    }
  },
  "synthesis": {
    "executive_summary": "Reviewed 10 papers across 1 venues. We summarize methods, results, and limitations, and identify common gaps.",
    "gaps": [
      "Few works report comparisons against strong baselines."
    ],
    "future_work": [
      "Open-sourcing code and datasets",
      "Larger, diverse cohorts",
      "Robust baseline comparisons"
    ]
  },
  "artifacts": {
    "markdown_path": "outputs\\review_zero-shot-cell-type-annotation-with-geneformer-foundation-model-langcell.md",
    "json_path": "outputs\\review_zero-shot-cell-type-annotation-with-geneformer-foundation-model-langcell.json",
    "csv_path": "outputs\\papers_zero-shot-cell-type-annotation-with-geneformer-foundation-model-langcell.csv"
  },
  "created_at": "2025-09-13T06:23:40.281148"
}
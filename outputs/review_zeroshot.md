## Executive summary

Reviewed 10 papers across 1 venues. We summarize methods, results, and limitations, and identify common gaps.

## Comparative matrix

| Paper | Venue | Year | Citations | Methods | Results | Limitations |
| --- | --- | --- | --- | --- | --- | --- |
| LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners | arXiv | 2025 |  |  |  |  |
| Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator
  Roles Assessed by Motivational Interviewing Criteria | arXiv | 2025 |  |  |  |  |
| Zeroshot Listwise Learning to Rank Algorithm for Recommendation | arXiv | 2024 |  |  |  |  |
| Annotation Free Semantic Segmentation with Vision Foundation Models | arXiv | 2024 |  |  |  |  |
| Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised
  Landmark Discovery | arXiv | 2024 |  |  |  |  |
| Paying More Attention to Source Context: Mitigating Unfaithful
  Translations from Large Language Model | arXiv | 2024 |  |  |  |  |
| CLIP-Decoder : ZeroShot Multilabel Classification using Multimodal CLIP
  Aligned Representation | arXiv | 2024 |  |  |  |  |
| Building Efficient Universal Classifiers with Natural Language Inference | arXiv | 2023 |  |  |  |  |
| InheritSumm: A General, Versatile and Compact Summarizer by Distilling
  from GPT | arXiv | 2023 |  |  |  |  |
| LogitMat : Zeroshot Learning Algorithm for Recommender Systems without
  Transfer Learning or Pretrained Models | arXiv | 2023 |  |  |  |  |


## Mini-reviews

### LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners

arXiv, 2025, Yu He; Zihan Yao; Chentao Song; Tianyu Qi; Jun Liu; Ming Li; Qing Huang

**TL;DR**

Cognitive Diagnosis (CD) has become a critical task in AI-empowered
education, supporting personalized learning by accurately assessing students'
cognitive states. However, traditional CD models often struggle in cold-start
scenarios due to the lack of student-exercise interactio...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Cognitive Diagnosis (CD) has become a critical task in AI-empowered
education, supporting personalized learning by accurately assessing students'
cognitive states. However, traditional CD models often (abstract)

### Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator
  Roles Assessed by Motivational Interviewing Criteria

arXiv, 2025, Keita Kiuchi; Yoshikazu Fujimoto; Hideyuki Goto; Tomonori Hosokawa; Makoto Nishimura; Yosuke Sato; Izumi Sezai

**TL;DR**

This study provides the first comprehensive evaluation of large language
model (LLM) performance across three counseling roles in Japanese-language
therapeutic contexts. We simultaneously assessed counselor artificial
intelligence (AI) systems (GPT-4-turbo with zeroshot prompting...

**Critique**

- overclaiming: Claims strong superiority; check against baselines in paper. (severity: medium)
- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> This study provides the first comprehensive evaluation of large language
model (LLM) performance across three counseling roles in Japanese-language
therapeutic contexts. We simultaneously assessed cou (abstract)

### Zeroshot Listwise Learning to Rank Algorithm for Recommendation

arXiv, 2024, Hao Wang

**TL;DR**

Learning to rank is a rare technology compared with other techniques such as
deep neural networks. The number of experts in the field is roughly 1/6 of the
number of professionals in deep learning. Being an effective ranking
methodology, learning to rank has been widely used in t...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Learning to rank is a rare technology compared with other techniques such as
deep neural networks. The number of experts in the field is roughly 1/6 of the
number of professionals in deep learning (abstract)

### Annotation Free Semantic Segmentation with Vision Foundation Models

arXiv, 2024, Soroush Seifi; Daniel Olmeda Reino; Fabien Despinoy; Rahaf Aljundi

**TL;DR**

Semantic Segmentation is one of the most challenging vision tasks, usually
requiring large amounts of training data with expensive pixel level
annotations. With the success of foundation models and especially
vision-language models, recent works attempt to achieve zeroshot semant...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Semantic Segmentation is one of the most challenging vision tasks, usually
requiring large amounts of training data with expensive pixel level
annotations. With the success of foundation models and es (abstract)

### Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised
  Landmark Discovery

arXiv, 2024, Siddharth Tourani; Ahmed Alwheibi; Arif Mahmood; Muhammad Haris Khan

**TL;DR**

Unsupervised landmarks discovery (ULD) for an object category is a
challenging computer vision problem. In pursuit of developing a robust ULD
framework, we explore the potential of a recent paradigm of self-supervised
learning algorithms, known as diffusion models. Some recent wo...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Unsupervised landmarks discovery (ULD) for an object category is a
challenging computer vision problem. In pursuit of developing a robust ULD
framework, we explore the potential of a recent paradigm o (abstract)

### Paying More Attention to Source Context: Mitigating Unfaithful
  Translations from Large Language Model

arXiv, 2024, Hongbin Zhang; Kehai Chen; Xuefeng Bai; Yang Xiang; Min Zhang

**TL;DR**

Large language models (LLMs) have showcased impressive multilingual machine
translation ability. However, unlike encoder-decoder style models, decoder-only
LLMs lack an explicit alignment between source and target contexts. Analyzing
contribution scores during generation processe...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Large language models (LLMs) have showcased impressive multilingual machine
translation ability. However, unlike encoder-decoder style models, decoder-only
LLMs lack an explicit alignment between sour (abstract)

### CLIP-Decoder : ZeroShot Multilabel Classification using Multimodal CLIP
  Aligned Representation

arXiv, 2024, Muhammad Ali; Salman Khan

**TL;DR**

Multi-label classification is an essential task utilized in a wide variety of
real-world applications. Multi-label zero-shot learning is a method for
classifying images into multiple unseen categories for which no training data
is available, while in general zero-shot situations,...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Multi-label classification is an essential task utilized in a wide variety of
real-world applications. Multi-label zero-shot learning is a method for
classifying images into multiple unseen categories (abstract)

### Building Efficient Universal Classifiers with Natural Language Inference

arXiv, 2023, Moritz Laurer; Wouter van Atteveldt; Andreu Casas; Kasper Welbers

**TL;DR**

Generative Large Language Models (LLMs) have become the mainstream choice for
fewshot and zeroshot learning thanks to the universality of text generation.
Many users, however, do not need the broad capabilities of generative LLMs when
they only want to automate a classification t...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Generative Large Language Models (LLMs) have become the mainstream choice for
fewshot and zeroshot learning thanks to the universality of text generation. Many users, however, do not need the broad ca (abstract)

### InheritSumm: A General, Versatile and Compact Summarizer by Distilling
  from GPT

arXiv, 2023, Yichong Xu; Ruochen Xu; Dan Iter; Yang Liu; Shuohang Wang; Chenguang Zhu; Michael Zeng

**TL;DR**

While large models such as GPT-3 demonstrate exceptional performance in
zeroshot and fewshot summarization tasks, their extensive serving and
fine-tuning costs hinder their utilization in various applications. Conversely,
previous studies have found that although automatic metric...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> While large models such as GPT-3 demonstrate exceptional performance in
zeroshot and fewshot summarization tasks, their extensive serving and
fine-tuning costs hinder their utilization in various appl (abstract)

### LogitMat : Zeroshot Learning Algorithm for Recommender Systems without
  Transfer Learning or Pretrained Models

arXiv, 2023, Hao Wang

**TL;DR**

Recommender system is adored in the internet industry as one of the most
profitable technologies. Unlike other sectors such as fraud detection in the
Fintech industry, recommender system is both deep and broad. In recent years,
many researchers start to focus on the cold-start pr...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Recommender system is adored in the internet industry as one of the most
profitable technologies. Unlike other sectors such as fraud detection in the
Fintech industry, recommender system is both deep  (abstract)

## Gaps & future work

- Few works report comparisons against strong baselines.
- Open-sourcing code and datasets
- Larger, diverse cohorts
- Robust baseline comparisons

### References

- Yu He, Zihan Yao, Chentao Song, Tianyu Qi, Jun Liu, Ming Li, Qing Huang. (2025) LMCD: Language Models are Zeroshot Cognitive Diagnosis Learners. arXiv. http://arxiv.org/abs/2505.21239v1
- Keita Kiuchi, Yoshikazu Fujimoto, Hideyuki Goto, Tomonori Hosokawa, Makoto Nishimura, Yosuke Sato, Izumi Sezai. (2025) Evaluating AI Counseling in Japanese: Counselor, Client, and Evaluator
  Roles Assessed by Motivational Interviewing Criteria. arXiv. http://arxiv.org/abs/2507.02950v2
- Hao Wang. (2024) Zeroshot Listwise Learning to Rank Algorithm for Recommendation. arXiv. http://arxiv.org/abs/2409.13703v1
- Soroush Seifi, Daniel Olmeda Reino, Fabien Despinoy, Rahaf Aljundi. (2024) Annotation Free Semantic Segmentation with Vision Foundation Models. arXiv. http://arxiv.org/abs/2403.09307v3
- Siddharth Tourani, Ahmed Alwheibi, Arif Mahmood, Muhammad Haris Khan. (2024) Pose-Guided Self-Training with Two-Stage Clustering for Unsupervised
  Landmark Discovery. arXiv. http://arxiv.org/abs/2403.16194v1
- Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang. (2024) Paying More Attention to Source Context: Mitigating Unfaithful
  Translations from Large Language Model. arXiv. http://arxiv.org/abs/2406.07036v1
- Muhammad Ali, Salman Khan. (2024) CLIP-Decoder : ZeroShot Multilabel Classification using Multimodal CLIP
  Aligned Representation. arXiv. http://arxiv.org/abs/2406.14830v1
- Moritz Laurer, Wouter van Atteveldt, Andreu Casas, Kasper Welbers. (2023) Building Efficient Universal Classifiers with Natural Language Inference. arXiv. http://arxiv.org/abs/2312.17543v2
- Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuohang Wang, Chenguang Zhu, Michael Zeng. (2023) InheritSumm: A General, Versatile and Compact Summarizer by Distilling
  from GPT. arXiv. http://arxiv.org/abs/2305.13083v1
- Hao Wang. (2023) LogitMat : Zeroshot Learning Algorithm for Recommender Systems without
  Transfer Learning or Pretrained Models. arXiv. http://arxiv.org/abs/2307.05680v1


## Executive summary

Reviewed 25 papers across 4 venues. We summarize methods, results, and limitations, and identify common gaps.

## Comparative matrix

| Paper | Venue | Year | Citations | Methods | Results | Limitations |
| --- | --- | --- | --- | --- | --- | --- |
| Prompt learning with bounding box constraints for medical image
  segmentation | arXiv | 2025 |  |  |  |  |
| No Free Lunch in Annotation either: An objective evaluation of
  foundation models for streamlining annotation in animal tracking | arXiv | 2025 |  |  |  |  |
| Foundation X: Integrating Classification, Localization, and Segmentation
  through Lock-Release Pretraining Strategy for Chest X-ray Analysis | arXiv | 2025 |  |  |  |  |
| Towards Auto-Annotation from Annotation Guidelines: A Benchmark through
  3D LiDAR Detection | arXiv | 2025 |  |  |  |  |
| Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered
  All-in-SAM Model | arXiv | 2025 |  |  |  |  |
| scExtract: leveraging large language models for fully automated single-cell RNA-seq data annotation and prior-informed multi-dataset integration. | Genome biology | 2025 |  |  |  |  |
| Annotation Free Semantic Segmentation with Vision Foundation Models | arXiv | 2024 |  |  |  |  |
| Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment
  Anything Model for Crowd-Sourcing Medical Image Annotations | arXiv | 2024 |  |  |  |  |
| Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model
  Performance and Annotation Cost | arXiv | 2024 |  |  |  |  |
| PhilEO Bench: Evaluating Geo-Spatial Foundation Models | arXiv | 2024 |  |  |  |  |
| Zero-shot prompt-based classification: topic labeling in times of
  foundation models in German Tweets | arXiv | 2024 |  |  |  |  |
| Video Annotator: A framework for efficiently building video classifiers
  using vision-language models and active learning | arXiv | 2024 |  |  |  |  |
| Efficient and Scalable Fine-Tune of Language Models for Genome
  Understanding | arXiv | 2024 |  |  |  |  |
| UrFound: Towards Universal Retinal Foundation Models via
  Knowledge-Guided Masked Modeling | arXiv | 2024 |  |  |  |  |
| Foundation Model Assisted Automatic Speech Emotion Recognition:
  Transcribing, Annotating, and Augmenting | arXiv | 2023 |  |  |  |  |
| Zero-Shot Segmentation of Eye Features Using the Segment Anything Model
  (SAM) | arXiv | 2023 |  |  |  |  |
| Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks | arXiv | 2021 |  |  |  |  |
| Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for
  VFSS Segmentations | arXiv | 2025 |  |  |  |  |
| ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset
  for Laparoscopic Surgical Instruments | arXiv | 2025 |  |  |  |  |
| FMG-Det: Foundation Model Guided Robust Object Detection | arXiv | 2025 |  |  |  |  |
| scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis. | bioRxiv : the preprint server for biology | 2025 |  |  |  |  |
| FPCAM: A Weighted Dictionary-Driven Model for Single-Cell Annotation in Pulmonary Fibrosis. | Biology | 2025 |  |  |  |  |
| FMARS: Annotating Remote Sensing Images for Disaster Management using
  Foundation Models | arXiv | 2024 |  |  |  |  |
| Beyond Pixel-Wise Supervision for Medical Image Segmentation: From
  Traditional Models to Foundation Models | arXiv | 2024 |  |  |  |  |
| The devil is in the object boundary: towards annotation-free instance
  segmentation using Foundation Models | arXiv | 2024 |  |  |  |  |


## Mini-reviews

### Prompt learning with bounding box constraints for medical image
  segmentation

arXiv, 2025, Mélanie Gaillochet; Mehrdad Noori; Sahar Dastani; Christian Desrosiers; Hervé Lombaert

**TL;DR**

Pixel-wise annotations are notoriously labourious and costly to obtain in the
medical domain. To mitigate this burden, weakly supervised approaches based on
bounding box annotations-much easier to acquire-offer a practical alternative.
Vision foundation models have recently shown...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Pixel-wise annotations are notoriously labourious and costly to obtain in the
medical domain. To mitigate this burden, weakly supervised approaches based on
bounding box annotations-much easier to acq (abstract)

### No Free Lunch in Annotation either: An objective evaluation of
  foundation models for streamlining annotation in animal tracking

arXiv, 2025, Emil Mededovic; Valdy Laurentius; Yuli Wu; Marcin Kopaczka; Zhu Chen; Mareike Schulz; René Tolba; Johannes Stegmaier

**TL;DR**

We analyze the capabilities of foundation models addressing the tedious task
of generating annotations for animal tracking. Annotating a large amount of
data is vital and can be a make-or-break factor for the robustness of a
tracking model. Robustness is particularly crucial in a...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> We analyze the capabilities of foundation models addressing the tedious task
of generating annotations for animal tracking. Annotating a large amount of
data is vital and can be a make-or-break factor (abstract)

### Foundation X: Integrating Classification, Localization, and Segmentation
  through Lock-Release Pretraining Strategy for Chest X-ray Analysis

arXiv, 2025, Nahid Ul Islam; DongAo Ma; Jiaxuan Pang; Shivasakthi Senthil Velan; Michael Gotway; Jianming Liang

**TL;DR**

Developing robust and versatile deep-learning models is essential for
enhancing diagnostic accuracy and guiding clinical interventions in medical
imaging, but it requires a large amount of annotated data. The advancement of
deep learning has facilitated the creation of numerous m...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Developing robust and versatile deep-learning models is essential for
enhancing diagnostic accuracy and guiding clinical interventions in medical
imaging, but it requires a large amount of annotated d (abstract)

### Towards Auto-Annotation from Annotation Guidelines: A Benchmark through
  3D LiDAR Detection

arXiv, 2025, Yechi Ma; Wei Hua; Shu Kong

**TL;DR**

A crucial yet under-appreciated prerequisite in machine learning solutions
for real-applications is data annotation: human annotators are hired to
manually label data according to detailed, expert-crafted guidelines. This is
often a laborious, tedious, and costly process. To stud...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> A crucial yet under-appreciated prerequisite in machine learning solutions
for real-applications is data annotation: human annotators are hired to
manually label data according to detailed, expert-cra (abstract)

### Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered
  All-in-SAM Model

arXiv, 2025, Xueyuan Li; Can Cui; Ruining Deng; Yucheng Tang; Quan Liu; Tianyuan Yao; Shunxing Bao; Naweed Chowdhury; Haichun Yang; Yuankai Huo

**TL;DR**

Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentation through two primary methods:
prompt-based zero-shot segmentation and the use...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentat (abstract)

### scExtract: leveraging large language models for fully automated single-cell RNA-seq data annotation and prior-informed multi-dataset integration.

Genome biology, 2025, Wu Y; Tang F

**TL;DR**

scExtract: leveraging large language models for fully automated single-cell RNA-seq data annotation and prior-informed multi-dataset integration.

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

### Annotation Free Semantic Segmentation with Vision Foundation Models

arXiv, 2024, Soroush Seifi; Daniel Olmeda Reino; Fabien Despinoy; Rahaf Aljundi

**TL;DR**

Semantic Segmentation is one of the most challenging vision tasks, usually
requiring large amounts of training data with expensive pixel level
annotations. With the success of foundation models and especially
vision-language models, recent works attempt to achieve zeroshot semant...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Semantic Segmentation is one of the most challenging vision tasks, usually
requiring large amounts of training data with expensive pixel level
annotations. With the success of foundation models and es (abstract)

### Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment
  Anything Model for Crowd-Sourcing Medical Image Annotations

arXiv, 2024, Pranav Kulkarni; Adway Kanhere; Dharmam Savani; Andrew Chan; Devina Chatterjee; Paul H. Yi; Vishwa S. Parekh

**TL;DR**

Curating annotations for medical image segmentation is a labor-intensive and
time-consuming task that requires domain expertise, resulting in "narrowly"
focused deep learning (DL) models with limited translational utility. Recently,
foundation models like the Segment Anything Mod...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Curating annotations for medical image segmentation is a labor-intensive and
time-consuming task that requires domain expertise, resulting in "narrowly"
focused deep learning (DL) models with limited  (abstract)

### Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model
  Performance and Annotation Cost

arXiv, 2024, Oana Ignat; Longju Bai; Joan Nwatu; Rada Mihalcea

**TL;DR**

Current foundation models have shown impressive performance across various
tasks. However, several studies have revealed that these models are not
effective for everyone due to the imbalanced geographical and economic
representation of the data used in the training process. Most ...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Current foundation models have shown impressive performance across various
tasks. However, several studies have revealed that these models are not
effective for everyone due to the imbalanced geograph (abstract)

### PhilEO Bench: Evaluating Geo-Spatial Foundation Models

arXiv, 2024, Casper Fibaek; Luke Camilleri; Andreas Luyts; Nikolaos Dionelis; Bertrand Le Saux

**TL;DR**

Massive amounts of unlabelled data are captured by Earth Observation (EO)
satellites, with the Sentinel-2 constellation generating 1.6 TB of data daily.
This makes Remote Sensing a data-rich domain well suited to Machine Learning
(ML) solutions. However, a bottleneck in applying ...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Massive amounts of unlabelled data are captured by Earth Observation (EO)
satellites, with the Sentinel-2 constellation generating 1. 6 TB of data daily (abstract)

### Zero-shot prompt-based classification: topic labeling in times of
  foundation models in German Tweets

arXiv, 2024, Simon Münker; Kai Kugler; Achim Rettinger

**TL;DR**

Filtering and annotating textual data are routine tasks in many areas, like
social media or news analytics. Automating these tasks allows to scale the
analyses wrt. speed and breadth of content covered and decreases the manual
effort required. Due to technical advancements in Nat...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Filtering and annotating textual data are routine tasks in many areas, like
social media or news analytics. Automating these tasks allows to scale the
analyses wrt (abstract)

### Video Annotator: A framework for efficiently building video classifiers
  using vision-language models and active learning

arXiv, 2024, Amir Ziai; Aneesh Vartakavi

**TL;DR**

High-quality and consistent annotations are fundamental to the successful
development of robust machine learning models. Traditional data annotation
methods are resource-intensive and inefficient, often leading to a reliance on
third-party annotators who are not the domain expert...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> High-quality and consistent annotations are fundamental to the successful
development of robust machine learning models. Traditional data annotation
methods are resource-intensive and inefficient, oft (abstract)

### Efficient and Scalable Fine-Tune of Language Models for Genome
  Understanding

arXiv, 2024, Huixin Zhan; Ying Nian Wu; Zijun Zhang

**TL;DR**

Although DNA foundation models have advanced the understanding of genomes,
they still face significant challenges in the limited scale and diversity of
genomic data. This limitation starkly contrasts with the success of natural
language foundation models, which thrive on substant...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Although DNA foundation models have advanced the understanding of genomes,
they still face significant challenges in the limited scale and diversity of
genomic data. This limitation starkly contrasts  (abstract)

### UrFound: Towards Universal Retinal Foundation Models via
  Knowledge-Guided Masked Modeling

arXiv, 2024, Kai Yu; Yang Zhou; Yang Bai; Zhi Da Soh; Xinxing Xu; Rick Siow Mong Goh; Ching-Yu Cheng; Yong Liu

**TL;DR**

Retinal foundation models aim to learn generalizable representations from
diverse retinal images, facilitating label-efficient model adaptation across
various ophthalmic tasks. Despite their success, current retinal foundation
models are generally restricted to a single imaging m...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Retinal foundation models aim to learn generalizable representations from
diverse retinal images, facilitating label-efficient model adaptation across
various ophthalmic tasks. Despite their success,  (abstract)

### Foundation Model Assisted Automatic Speech Emotion Recognition:
  Transcribing, Annotating, and Augmenting

arXiv, 2023, Tiantian Feng; Shrikanth Narayanan

**TL;DR**

Significant advances are being made in speech emotion recognition (SER) using
deep learning models. Nonetheless, training SER systems remains challenging,
requiring both time and costly resources. Like many other machine learning
tasks, acquiring datasets for SER requires substan...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Significant advances are being made in speech emotion recognition (SER) using
deep learning models. Nonetheless, training SER systems remains challenging,
requiring both time and costly resources (abstract)

### Zero-Shot Segmentation of Eye Features Using the Segment Anything Model
  (SAM)

arXiv, 2023, Virmarie Maquiling; Sean Anthony Byrne; Diederick C. Niehorster; Marcus Nyström; Enkelejda Kasneci

**TL;DR**

The advent of foundation models signals a new era in artificial intelligence.
The Segment Anything Model (SAM) is the first foundation model for image
segmentation. In this study, we evaluate SAM's ability to segment features from
eye images recorded in virtual reality setups. Th...

**Critique**

- overclaiming: Claims strong superiority; check against baselines in paper. (severity: medium)
- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image
segmentation (abstract)

### Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks

arXiv, 2021, Paul Röttger; Bertie Vidgen; Dirk Hovy; Janet B. Pierrehumbert

**TL;DR**

Labelled data is the foundation of most natural language processing tasks.
However, labelling data is difficult and there often are diverse valid beliefs
about what the correct data labels should be. So far, dataset creators have
acknowledged annotator subjectivity, but rarely ac...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Labelled data is the foundation of most natural language processing tasks. However, labelling data is difficult and there often are diverse valid beliefs
about what the correct data labels should be (abstract)

### Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for
  VFSS Segmentations

arXiv, 2025, Chengxi Zeng; David Smithard; Alberto M Gambaruto; Tilo Burghardt

**TL;DR**

Vision foundation models have demonstrated exceptional generalization
capabilities in segmentation tasks for both generic and specialized images.
However, a performance gap persists between foundation models and
task-specific, specialized models. Fine-tuning foundation models on ...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Vision foundation models have demonstrated exceptional generalization
capabilities in segmentation tasks for both generic and specialized images. However, a performance gap persists between foundation (abstract)

### ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset
  for Laparoscopic Surgical Instruments

arXiv, 2025, Zhe Han; Charlie Budd; Gongyu Zhang; Huanyu Tian; Christos Bergeles; Tom Vercauteren

**TL;DR**

Localisation of surgical tools constitutes a foundational building block for
computer-assisted interventional technologies. Works in this field typically
focus on training deep learning models to perform segmentation tasks.
Performance of learning-based approaches is limited by t...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Localisation of surgical tools constitutes a foundational building block for
computer-assisted interventional technologies. Works in this field typically
focus on training deep learning models to perf (abstract)

### FMG-Det: Foundation Model Guided Robust Object Detection

arXiv, 2025, Darryl Hannan; Timothy Doster; Henry Kvinge; Adam Attarian; Yijing Watkins

**TL;DR**

Collecting high quality data for object detection tasks is challenging due to
the inherent subjectivity in labeling the boundaries of an object. This makes
it difficult to not only collect consistent annotations across a dataset but
also to validate them, as no two annotators are...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Collecting high quality data for object detection tasks is challenging due to
the inherent subjectivity in labeling the boundaries of an object. This makes
it difficult to not only collect consistent  (abstract)

### scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis.

bioRxiv : the preprint server for biology, 2025, Liu T; Chen T; Zheng W; Luo X; Chen Y; Zhao H

**TL;DR**

scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis.

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

### FPCAM: A Weighted Dictionary-Driven Model for Single-Cell Annotation in Pulmonary Fibrosis.

Biology, 2025, Liu G; Shi Y; Huang H; Xiao N; Liu C; Zhao H; Xing Y; Cai L

**TL;DR**

FPCAM: A Weighted Dictionary-Driven Model for Single-Cell Annotation in Pulmonary Fibrosis.

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

### FMARS: Annotating Remote Sensing Images for Disaster Management using
  Foundation Models

arXiv, 2024, Edoardo Arnaudo; Jacopo Lungo Vaschetti; Lorenzo Innocenti; Luca Barco; Davide Lisi; Vanina Fissore; Claudio Rossi

**TL;DR**

Very-High Resolution (VHR) remote sensing imagery is increasingly accessible,
but often lacks annotations for effective machine learning applications. Recent
foundation models like GroundingDINO and Segment Anything (SAM) provide
opportunities to automatically generate annotation...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Very-High Resolution (VHR) remote sensing imagery is increasingly accessible,
but often lacks annotations for effective machine learning applications. Recent
foundation models like GroundingDINO and S (abstract)

### Beyond Pixel-Wise Supervision for Medical Image Segmentation: From
  Traditional Models to Foundation Models

arXiv, 2024, Yuyan Shi; Jialu Ma; Jin Yang; Shasha Wang; Yichi Zhang

**TL;DR**

Medical image segmentation plays an important role in many image-guided
clinical approaches. However, existing segmentation algorithms mostly rely on
the availability of fully annotated images with pixel-wise annotations for
training, which can be both labor-intensive and experti...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Medical image segmentation plays an important role in many image-guided
clinical approaches. However, existing segmentation algorithms mostly rely on
the availability of fully annotated images with pi (abstract)

### The devil is in the object boundary: towards annotation-free instance
  segmentation using Foundation Models

arXiv, 2024, Cheng Shi; Sibei Yang

**TL;DR**

Foundation models, pre-trained on a large amount of data have demonstrated
impressive zero-shot capabilities in various downstream tasks. However, in
object detection and instance segmentation, two fundamental computer vision
tasks heavily reliant on extensive human annotations, ...

**Critique**

- missing_baselines: Results do not clearly compare against established baselines. (severity: low)
- reproducibility: No mention of code/data availability or reproducibility. (severity: medium)

**Grounding quotes**

> Foundation models, pre-trained on a large amount of data have demonstrated
impressive zero-shot capabilities in various downstream tasks. However, in
object detection and instance segmentation, two fu (abstract)

## Gaps & future work

- Few works report comparisons against strong baselines.
- Open-sourcing code and datasets
- Larger, diverse cohorts
- Robust baseline comparisons

### References

- Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert. (2025) Prompt learning with bounding box constraints for medical image
  segmentation. arXiv. http://arxiv.org/abs/2507.02743v1
- Emil Mededovic, Valdy Laurentius, Yuli Wu, Marcin Kopaczka, Zhu Chen, Mareike Schulz, René Tolba, Johannes Stegmaier. (2025) No Free Lunch in Annotation either: An objective evaluation of
  foundation models for streamlining annotation in animal tracking. arXiv. http://arxiv.org/abs/2502.03907v1
- Nahid Ul Islam, DongAo Ma, Jiaxuan Pang, Shivasakthi Senthil Velan, Michael Gotway, Jianming Liang. (2025) Foundation X: Integrating Classification, Localization, and Segmentation
  through Lock-Release Pretraining Strategy for Chest X-ray Analysis. arXiv. http://arxiv.org/abs/2503.09860v1
- Yechi Ma, Wei Hua, Shu Kong. (2025) Towards Auto-Annotation from Annotation Guidelines: A Benchmark through
  3D LiDAR Detection. arXiv. http://arxiv.org/abs/2506.02914v1
- Xueyuan Li, Can Cui, Ruining Deng, Yucheng Tang, Quan Liu, Tianyuan Yao, Shunxing Bao, Naweed Chowdhury, Haichun Yang, Yuankai Huo. (2025) Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered
  All-in-SAM Model. arXiv. http://arxiv.org/abs/2508.15751v1
- Wu Y, Tang F. (2025) scExtract: leveraging large language models for fully automated single-cell RNA-seq data annotation and prior-informed multi-dataset integration.. Genome biology. https://pubmed.ncbi.nlm.nih.gov/40537825/
- Soroush Seifi, Daniel Olmeda Reino, Fabien Despinoy, Rahaf Aljundi. (2024) Annotation Free Semantic Segmentation with Vision Foundation Models. arXiv. http://arxiv.org/abs/2403.09307v3
- Pranav Kulkarni, Adway Kanhere, Dharmam Savani, Andrew Chan, Devina Chatterjee, Paul H. Yi, Vishwa S. Parekh. (2024) Anytime, Anywhere, Anyone: Investigating the Feasibility of Segment
  Anything Model for Crowd-Sourcing Medical Image Annotations. arXiv. http://arxiv.org/abs/2403.15218v1
- Oana Ignat, Longju Bai, Joan Nwatu, Rada Mihalcea. (2024) Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model
  Performance and Annotation Cost. arXiv. http://arxiv.org/abs/2403.07687v1
- Casper Fibaek, Luke Camilleri, Andreas Luyts, Nikolaos Dionelis, Bertrand Le Saux. (2024) PhilEO Bench: Evaluating Geo-Spatial Foundation Models. arXiv. http://arxiv.org/abs/2401.04464v2
- Simon Münker, Kai Kugler, Achim Rettinger. (2024) Zero-shot prompt-based classification: topic labeling in times of
  foundation models in German Tweets. arXiv. http://arxiv.org/abs/2406.18239v1
- Amir Ziai, Aneesh Vartakavi. (2024) Video Annotator: A framework for efficiently building video classifiers
  using vision-language models and active learning. arXiv. http://arxiv.org/abs/2402.06560v1
- Huixin Zhan, Ying Nian Wu, Zijun Zhang. (2024) Efficient and Scalable Fine-Tune of Language Models for Genome
  Understanding. arXiv. http://arxiv.org/abs/2402.08075v1
- Kai Yu, Yang Zhou, Yang Bai, Zhi Da Soh, Xinxing Xu, Rick Siow Mong Goh, Ching-Yu Cheng, Yong Liu. (2024) UrFound: Towards Universal Retinal Foundation Models via
  Knowledge-Guided Masked Modeling. arXiv. http://arxiv.org/abs/2408.05618v1
- Tiantian Feng, Shrikanth Narayanan. (2023) Foundation Model Assisted Automatic Speech Emotion Recognition:
  Transcribing, Annotating, and Augmenting. arXiv. http://arxiv.org/abs/2309.08108v1
- Virmarie Maquiling, Sean Anthony Byrne, Diederick C. Niehorster, Marcus Nyström, Enkelejda Kasneci. (2023) Zero-Shot Segmentation of Eye Features Using the Segment Anything Model
  (SAM). arXiv. http://arxiv.org/abs/2311.08077v2
- Paul Röttger, Bertie Vidgen, Dirk Hovy, Janet B. Pierrehumbert. (2021) Two Contrasting Data Annotation Paradigms for Subjective NLP Tasks. arXiv. http://arxiv.org/abs/2112.07475v2
- Chengxi Zeng, David Smithard, Alberto M Gambaruto, Tilo Burghardt. (2025) Tuning Vision Foundation Model via Test-Time Prompt-Guided Training for
  VFSS Segmentations. arXiv. http://arxiv.org/abs/2501.18474v1
- Zhe Han, Charlie Budd, Gongyu Zhang, Huanyu Tian, Christos Bergeles, Tom Vercauteren. (2025) ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset
  for Laparoscopic Surgical Instruments. arXiv. http://arxiv.org/abs/2508.21096v1
- Darryl Hannan, Timothy Doster, Henry Kvinge, Adam Attarian, Yijing Watkins. (2025) FMG-Det: Foundation Model Guided Robust Object Detection. arXiv. http://arxiv.org/abs/2505.23726v1
- Liu T, Chen T, Zheng W, Luo X, Chen Y, Zhao H. (2025) scELMo: Embeddings from Language Models are Good Learners for Single-cell Data Analysis.. bioRxiv : the preprint server for biology. https://pubmed.ncbi.nlm.nih.gov/40894586/
- Liu G, Shi Y, Huang H, Xiao N, Liu C, Zhao H, Xing Y, Cai L. (2025) FPCAM: A Weighted Dictionary-Driven Model for Single-Cell Annotation in Pulmonary Fibrosis.. Biology. https://pubmed.ncbi.nlm.nih.gov/40427668/
- Edoardo Arnaudo, Jacopo Lungo Vaschetti, Lorenzo Innocenti, Luca Barco, Davide Lisi, Vanina Fissore, Claudio Rossi. (2024) FMARS: Annotating Remote Sensing Images for Disaster Management using
  Foundation Models. arXiv. http://arxiv.org/abs/2405.20109v2
- Yuyan Shi, Jialu Ma, Jin Yang, Shasha Wang, Yichi Zhang. (2024) Beyond Pixel-Wise Supervision for Medical Image Segmentation: From
  Traditional Models to Foundation Models. arXiv. http://arxiv.org/abs/2404.13239v1
- Cheng Shi, Sibei Yang. (2024) The devil is in the object boundary: towards annotation-free instance
  segmentation using Foundation Models. arXiv. http://arxiv.org/abs/2404.11957v1

